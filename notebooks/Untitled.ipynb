{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf8\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from collections import defaultdict\n",
    "import srsly\n",
    "\n",
    "from spacy.errors import Errors\n",
    "from spacy.compat import basestring_\n",
    "from spacy.util import ensure_path\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import Matcher, PhraseMatcher\n",
    "\n",
    "\n",
    "class EntityRuler(object):\n",
    "    \"\"\"The EntityRuler lets you add spans to the `Doc.ents` using token-based\n",
    "    rules or exact phrase matches. It can be combined with the statistical\n",
    "    `EntityRecognizer` to boost accuracy, or used on its own to implement a\n",
    "    purely rule-based entity recognition system. After initialization, the\n",
    "    component is typically added to the pipeline using `nlp.add_pipe`.\n",
    "\n",
    "    DOCS: https://spacy.io/api/entityruler\n",
    "    USAGE: https://spacy.io/usage/rule-based-matching#entityruler\n",
    "    \"\"\"\n",
    "\n",
    "    name = \"entity_ruler\"\n",
    "\n",
    "    def __init__(self, nlp, **cfg):\n",
    "        \"\"\"Initialize the entitiy ruler. If patterns are supplied here, they\n",
    "        need to be a list of dictionaries with a `\"label\"` and `\"pattern\"`\n",
    "        key. A pattern can either be a token pattern (list) or a phrase pattern\n",
    "        (string). For example: `{'label': 'ORG', 'pattern': 'Apple'}`.\n",
    "\n",
    "        nlp (Language): The shared nlp object to pass the vocab to the matchers\n",
    "            and process phrase patterns.\n",
    "        patterns (iterable): Optional patterns to load in.\n",
    "        overwrite_ents (bool): If existing entities are present, e.g. entities\n",
    "            added by the model, overwrite them by matches if necessary.\n",
    "        **cfg: Other config parameters. If pipeline component is loaded as part\n",
    "            of a model pipeline, this will include all keyword arguments passed\n",
    "            to `spacy.load`.\n",
    "        RETURNS (EntityRuler): The newly constructed object.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#init\n",
    "        \"\"\"\n",
    "        self.nlp = nlp\n",
    "        self.overwrite = cfg.get(\"overwrite_ents\", False)\n",
    "        self.token_patterns = defaultdict(list)\n",
    "        self.phrase_patterns = defaultdict(list)\n",
    "        self.matcher = Matcher(nlp.vocab)\n",
    "        self.phrase_matcher = PhraseMatcher(nlp.vocab)\n",
    "        self.entity_id_sep = cfg.get('entity_id_sep', '|')\n",
    "        patterns = cfg.get(\"patterns\")\n",
    "        if patterns is not None:\n",
    "            self.add_patterns(patterns)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"The number of all patterns added to the entity ruler.\"\"\"\n",
    "        n_token_patterns = sum(len(p) for p in self.token_patterns.values())\n",
    "        n_phrase_patterns = sum(len(p) for p in self.phrase_patterns.values())\n",
    "        return n_token_patterns + n_phrase_patterns\n",
    "\n",
    "    def __contains__(self, label):\n",
    "        \"\"\"Whether a label is present in the patterns.\"\"\"\n",
    "        return label in self.token_patterns or label in self.phrase_patterns\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        \"\"\"Find matches in document and add them as entities.\n",
    "\n",
    "        doc (Doc): The Doc object in the pipeline.\n",
    "        RETURNS (Doc): The Doc with added entities, if available.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#call\n",
    "        \"\"\"\n",
    "        matches = list(self.matcher(doc)) + list(self.phrase_matcher(doc))\n",
    "        matches = set(\n",
    "            [(m_id, start, end) for m_id, start, end in matches if start != end]\n",
    "        )\n",
    "        get_sort_key = lambda m: (m[2] - m[1], m[1])\n",
    "        matches = sorted(matches, key=get_sort_key, reverse=True)\n",
    "        entities = list(doc.ents)\n",
    "        new_entities = []\n",
    "        seen_tokens = set()\n",
    "        for match_id, start, end in matches:\n",
    "            if any(t.ent_type for t in doc[start:end]) and not self.overwrite:\n",
    "                continue\n",
    "            # check for end - 1 here because boundaries are inclusive\n",
    "            if start not in seen_tokens and end - 1 not in seen_tokens:\n",
    "                if self.entity_ids:\n",
    "                    if not Span.has_extension('entity_id'):\n",
    "                        Span.set_extension('entity_id', default=None)\n",
    "\n",
    "                    label_ = self.nlp.vocab.strings[match_id]\n",
    "                    ent_label, ent_id = self.split_label(label_)\n",
    "                    span = Span(doc, start, end, label=ent_label)\n",
    "                    if ent_id:\n",
    "                        span._.entity_id = ent_id\n",
    "                else:\n",
    "                    span = span = Span(doc, start, end, label=match_id)\n",
    "                new_entities.append(span)\n",
    "                entities = [\n",
    "                    e for e in entities if not (e.start < end and e.end > start)\n",
    "                ]\n",
    "                seen_tokens.update(range(start, end))\n",
    "        doc.ents = entities + new_entities\n",
    "        return doc\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        \"\"\"All labels present in the match patterns.\n",
    "\n",
    "        RETURNS (set): The string labels.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#labels\n",
    "        \"\"\"\n",
    "        all_labels = set(self.token_patterns.keys())\n",
    "        all_labels.update(self.phrase_patterns.keys())\n",
    "        return tuple(all_labels)\n",
    "    \n",
    "    @property\n",
    "    def entity_ids(self):\n",
    "        \"\"\"All entity ids present in the match patterns meta dicts.\n",
    "\n",
    "        RETURNS (set): The string entity ids.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#labels\n",
    "        \"\"\"\n",
    "        all_entity_ids = set()\n",
    "        for l in self.labels:\n",
    "            if self.entity_id_sep in l:\n",
    "                _, ent_id = l.split(self.entity_id_sep)\n",
    "                all_entity_ids.add(ent_id)\n",
    "        return tuple(all_entity_ids)\n",
    "    \n",
    "    \n",
    "    def split_label(self, label):\n",
    "        if self.entity_id_sep in label:\n",
    "            ent_label, ent_id = label.split(self.entity_id_sep)\n",
    "        else:\n",
    "            ent_label = label\n",
    "            ent_id = None\n",
    "        \n",
    "        return ent_label, ent_id\n",
    "\n",
    "    def create_label(self, label, entity_id):\n",
    "        if isinstance(entity_id, basestring_):\n",
    "            label = '{}{}{}'.format(label, self.entity_id_sep, entity_id)\n",
    "        return label\n",
    "\n",
    "    @property\n",
    "    def patterns(self):\n",
    "        \"\"\"Get all patterns that were added to the entity ruler.\n",
    "\n",
    "        RETURNS (list): The original patterns, one dictionary per pattern.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#patterns\n",
    "        \"\"\"\n",
    "        all_patterns = []\n",
    "        for label, patterns in self.token_patterns.items():\n",
    "            for pattern in patterns:\n",
    "                ent_label, ent_id = self.split_label(label)\n",
    "                p = {\"label\": ent_label, \"pattern\": pattern}\n",
    "                if ent_id:\n",
    "                    p[\"id\"] = ent_id\n",
    "                all_patterns.append(p)\n",
    "        for label, patterns in self.phrase_patterns.items():\n",
    "            for pattern in patterns:\n",
    "                ent_label, ent_id = self.split_label(label)\n",
    "                p = {\"label\": ent_label, \"pattern\": pattern.text}\n",
    "                if ent_id:\n",
    "                    p[\"id\"] = ent_id\n",
    "                all_patterns.append(p)\n",
    "\n",
    "        return all_patterns\n",
    "\n",
    "    def add_patterns(self, patterns):\n",
    "        \"\"\"Add patterns to the entitiy ruler. A pattern can either be a token\n",
    "        pattern (list of dicts) or a phrase pattern (string). For example:\n",
    "        {'label': 'ORG', 'pattern': 'Apple'}\n",
    "        {'label': 'GPE', 'pattern': [{'lower': 'san'}, {'lower': 'francisco'}]}\n",
    "\n",
    "        patterns (list): The patterns to add.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#add_patterns\n",
    "        \"\"\"\n",
    "        for entry in patterns:\n",
    "            label = entry[\"label\"]\n",
    "            if 'id' in entry:\n",
    "                label = self.create_label(label, entry['id'])\n",
    "            pattern = entry[\"pattern\"]\n",
    "            if isinstance(pattern, basestring_):\n",
    "                self.phrase_patterns[label].append(self.nlp(pattern))\n",
    "            elif isinstance(pattern, list):\n",
    "                self.token_patterns[label].append(pattern)\n",
    "            else:\n",
    "                raise ValueError(Errors.E097.format(pattern=pattern))\n",
    "        for label, patterns in self.token_patterns.items():\n",
    "            self.matcher.add(label, None, *patterns)\n",
    "        for label, patterns in self.phrase_patterns.items():\n",
    "            self.phrase_matcher.add(label, None, *patterns)\n",
    "\n",
    "    def from_bytes(self, patterns_bytes, **kwargs):\n",
    "        \"\"\"Load the entity ruler from a bytestring.\n",
    "\n",
    "        patterns_bytes (bytes): The bytestring to load.\n",
    "        **kwargs: Other config paramters, mostly for consistency.\n",
    "        RETURNS (EntityRuler): The loaded entity ruler.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#from_bytes\n",
    "        \"\"\"\n",
    "        patterns = srsly.msgpack_loads(patterns_bytes)\n",
    "        self.add_patterns(patterns)\n",
    "        return self\n",
    "\n",
    "    def to_bytes(self, **kwargs):\n",
    "        \"\"\"Serialize the entity ruler patterns to a bytestring.\n",
    "\n",
    "        RETURNS (bytes): The serialized patterns.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#to_bytes\n",
    "        \"\"\"\n",
    "        return srsly.msgpack_dumps(self.patterns)\n",
    "\n",
    "    def from_disk(self, path, **kwargs):\n",
    "        \"\"\"Load the entity ruler from a file. Expects a file containing\n",
    "        newline-delimited JSON (JSONL) with one entry per line.\n",
    "\n",
    "        path (unicode / Path): The JSONL file to load.\n",
    "        **kwargs: Other config paramters, mostly for consistency.\n",
    "        RETURNS (EntityRuler): The loaded entity ruler.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#from_disk\n",
    "        \"\"\"\n",
    "        print('LOADING FROM DISK ENTITY RULER: ', path)\n",
    "        path = ensure_path(path)\n",
    "        path = path.with_suffix(\".jsonl\")\n",
    "        patterns = srsly.read_jsonl(path)\n",
    "        print(patterns)\n",
    "        self.add_patterns(patterns)\n",
    "        return self\n",
    "\n",
    "    def to_disk(self, path, **kwargs):\n",
    "        \"\"\"Save the entity ruler patterns to a directory. The patterns will be\n",
    "        saved as newline-delimited JSON (JSONL).\n",
    "\n",
    "        path (unicode / Path): The JSONL file to load.\n",
    "        **kwargs: Other config paramters, mostly for consistency.\n",
    "        RETURNS (EntityRuler): The loaded entity ruler.\n",
    "\n",
    "        DOCS: https://spacy.io/api/entityruler#to_disk\n",
    "        \"\"\"\n",
    "        path = ensure_path(path)\n",
    "        path = path.with_suffix(\".jsonl\")\n",
    "        srsly.write_jsonl(path, self.patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.pipeline import EntityRuler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    {'label': 'TECH_ORG', 'pattern': 'Apple', 'id':'a1'},\n",
    "    {'label': 'TECH_ORG', 'pattern': 'Google'},\n",
    "    {'label': 'GPE', 'pattern': [{'lower': 'san'}, {'lower': 'francisco'}], 'id': 'a3'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "my_ruler = EntityRuler(nlp)\n",
    "my_ruler.add_patterns(patterns)\n",
    "nlp.add_pipe(my_ruler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'GPE', 'pattern': [{'lower': 'san'}, {'lower': 'francisco'}]},\n",
       " {'label': 'TECH_ORG', 'pattern': 'Apple'},\n",
       " {'label': 'TECH_ORG', 'pattern': 'Google'}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_ruler.patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Apple', 6668960173413542989, 'TECH_ORG', 'a1'),\n",
       " ('Google', 6668960173413542989, 'TECH_ORG', None),\n",
       " ('San Francisco', 384, 'GPE', 'a3')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('Apple and Google are companies in San Francisco')\n",
    "\n",
    "[(e.text, e.label, e.label_, e._.entity_id) for e in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk('./entity_id_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('./entity_id_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['entity_ruler']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'GPE',\n",
       "  'pattern': [{'lower': 'san'}, {'lower': 'francisco'}],\n",
       "  'id': 'a3'},\n",
       " {'label': 'TECH_ORG', 'pattern': 'Apple', 'id': 'a1'},\n",
       " {'label': 'TECH_ORG', 'pattern': 'Google'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get_pipe('entity_ruler').patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = srsly.read_json('/mnt/c/users/kakh/Documents/AzureSearchJobSkillsDemo/functionapp_skills/_data/skills.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_skills = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sorted(skills):\n",
    "    ordered_skills[s] = skills[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.net',\n",
       "  [{'id': 'stackshare..net',\n",
       "    'sourceName': 'Stackshare Skills',\n",
       "    'displayName': '.NET',\n",
       "    'shortDescription': '.NET is a free, cross-platform, open source developer platform for building many different types of applications.',\n",
       "    'longDescription': '.NET is a general purpose development platform. With .NET, you can use multiple languages, editors, and libraries to build native applications for web, mobile, desktop, gaming, and IoT for Windows, macOS, Linux, Android, and more.',\n",
       "    'url': 'http://www.microsoft.com/net/'}]),\n",
       " ('1password',\n",
       "  [{'id': 'stackshare.1password',\n",
       "    'sourceName': 'Stackshare Skills',\n",
       "    'displayName': '1Password',\n",
       "    'shortDescription': 'A password manager and secure wallet for Mac, Windows, iOS, and Android.',\n",
       "    'longDescription': '1Password is the best password manager and secure wallet for Mac, Windows, iOS, and Android. Securely generate, store, and fill passwords and much more.',\n",
       "    'url': 'https://stackshare.io/1password'}]),\n",
       " ('3d',\n",
       "  [{'id': 'github.3d',\n",
       "    'sourceName': 'Github Topics',\n",
       "    'displayName': '3D',\n",
       "    'shortDescription': '3D modeling is the process of virtually developing the surface and structure of a 3D object.',\n",
       "    'longDescription': '3D modeling uses specialized software to create a digital model of a physical object. It is an aspect of 3D computer graphics, used for video games, 3D printing, and VR, among other applications.',\n",
       "    'url': 'https://www.github.com/topics/3d'}]),\n",
       " ('3d-reconstruction',\n",
       "  [{'id': 'ms-academic-graph.3d-reconstruction',\n",
       "    'sourceName': 'Microsoft Academic Graph',\n",
       "    'displayName': '3D reconstruction',\n",
       "    'shortDescription': 'In computer vision and computer graphics, 3D reconstruction is the process of capturing the shape and appearance of real objects. This process can be accomplished either by active or passive methods. If the model is allowed to change its shape in time, this is referred to as non-rigid or spatio-temporal reconstruction.',\n",
       "    'longDescription': '',\n",
       "    'url': 'https://preview.academic.microsoft.com/api/entity/109950114?entityType=7'}]),\n",
       " ('aboutness',\n",
       "  [{'id': 'ms-academic-graph.aboutness',\n",
       "    'sourceName': 'Microsoft Academic Graph',\n",
       "    'displayName': 'Aboutness',\n",
       "    'shortDescription': 'Aboutness is a term used in library and information science (LIS), linguistics, philosophy of language, and philosophy of mind. In LIS, it is often considered synonymous with subject (documents). In the philosophy of mind it has been often considered synonymous with intentionality, perhaps since John Searle (1983). In the philosophy of logic and language it is understood as the way a piece of text relates to a subject matter or topic.',\n",
       "    'longDescription': '',\n",
       "    'url': 'https://preview.academic.microsoft.com/api/entity/2780200193?entityType=7'}])]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ordered_skills.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "srsly.write_json('/mnt/c/users/kakh/Documents/AzureSearchJobSkillsDemo/functionapp_skills/_data/skills.json', ordered_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
